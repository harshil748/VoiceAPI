# VoiceAPI: Multi-lingual Text-to-Speech for Healthcare

A production-ready, multi-lingual Text-to-Speech system supporting **11 Indian languages** with **21 voice variants**, trained on 150+ hours of speech data. Built for maternal healthcare accessibility.

ğŸŒ **Live API**: [https://harshil748-voiceapi.hf.space](https://harshil748-voiceapi.hf.space)  
ğŸ“– **API Docs**: [https://harshil748-voiceapi.hf.space/docs](https://harshil748-voiceapi.hf.space/docs)  
ğŸ’» **GitHub**: [https://github.com/harshil748/VoiceAPI](https://github.com/harshil748/VoiceAPI)

---

## ğŸ¯ Project Overview

Built for the **Voice Tech for All Hackathon** to address linguistic barriers in rural Indian healthcare. The system converts medical instructions into natural speech across 11 languages, enabling accessible prenatal care guidance for non-literate populations.

## âœ¨ Key Features

- ğŸŒ **11 Indian Languages**: Hindi, Bengali, Marathi, Telugu, Kannada, Bhojpuri, Chhattisgarhi, Maithili, Magahi, English, Gujarati
- ğŸ¤ **21 Voice Variants**: Male & Female voices trained on 150+ hours of speech data
- ğŸ­ **Prosody Control**: 9 style presets (calm, happy, sad, slow, fast, etc.)
- âš¡ **Real-time Performance**: 0.3-0.9s inference on CPU hardware
- ğŸ”Œ **Production REST API**: FastAPI with automatic docs, CORS support
- ğŸ§  **Neural Architecture**: VITS + Meta MMS models with JIT optimization
- ğŸ“¦ **Deployed on HuggingFace Spaces**: Always-on, cloud-hosted API

---

## ğŸš€ Try It Now (No Installation Required)

### Test with Python

```python
import requests

# Use the live API
base_url = 'https://harshil748-voiceapi.hf.space/Get_Inference'

params = {
    'text': 'à¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤†à¤ª à¤•à¥ˆà¤¸à¥‡ à¤¹à¥ˆà¤‚?',  # Hindi text
    'lang': 'hindi',
}

# Upload any WAV file as speaker reference
with open('reference.wav', 'rb') as audio:
    response = requests.get(base_url, params=params, files={'speaker_wav': audio})

if response.status_code == 200:
    with open('output.wav', 'wb') as f:
        f.write(response.content)
    print("âœ… Audio saved as 'output.wav'")
```

### Test with cURL

```bash
curl -X GET "https://harshil748-voiceapi.hf.space/Get_Inference?text=àª¨àª®àª¸à«àª¤à«‡&lang=gujarati" \
  -F "speaker_wav=@reference.wav" \
  -o output.wav
```

### Test with Postman

1. **Method**: `GET`
2. **URL**: `https://harshil748-voiceapi.hf.space/Get_Inference`
3. **Params Tab**:
   - `text`: Your text in any supported language
   - `lang`: One of: hindi, bengali, marathi, telugu, kannada, gujarati, bhojpuri, chhattisgarhi, maithili, magahi, english
4. **Body Tab** â†’ `form-data`:
   - Key: `speaker_wav` (Type: File)
   - Value: Upload any `.wav` file
5. **Send** â†’ Save response as `.wav` file

---

## ğŸ¨ Supported Languages

| Language      | Code            | Male Voice | Female Voice | Sample Text                |
| ------------- | --------------- | ---------- | ------------ | -------------------------- |
| Hindi         | `hindi`         | âœ…         | âœ…           | à¤¨à¤®à¤¸à¥à¤¤à¥‡                     |
| Bengali       | `bengali`       | âœ…         | âœ…           | à¦¨à¦®à¦¸à§à¦•à¦¾à¦°                    |
| Marathi       | `marathi`       | âœ…         | âœ…           | à¤¨à¤®à¤¸à¥à¤•à¤¾à¤°                    |
| Telugu        | `telugu`        | âœ…         | âœ…           | à°¨à°®à°¸à±à°•à°¾à°°à°‚                   |
| Kannada       | `kannada`       | âœ…         | âœ…           | à²¨à²®à²¸à³à²•à²¾à²°                    |
| Gujarati      | `gujarati`      | âœ…         | -            | àª¨àª®àª¸à«àª¤à«‡                     |
| Bhojpuri      | `bhojpuri`      | âœ…         | âœ…           | à¤ªà¥à¤°à¤£à¤¾à¤®                     |
| Chhattisgarhi | `chhattisgarhi` | âœ…         | âœ…           | à¤¨à¤®à¤¸à¥à¤•à¤¾à¤°                    |
| Maithili      | `maithili`      | âœ…         | âœ…           | à¤ªà¥à¤°à¤£à¤¾à¤®                     |
| Magahi        | `magahi`        | âœ…         | âœ…           | à¤ªà¥à¤°à¤£à¤¾à¤®                     |
| English       | `english`       | âœ…         | âœ…           | hello (lowercase required) |

---

---

## ğŸ“¡ API Reference

### GET /Get_Inference

Converts text to speech in any supported Indian language.

**Endpoint**: `https://harshil748-voiceapi.hf.space/Get_Inference`

**Parameters**:

| Parameter     | Type   | Required | Description                                           |
| ------------- | ------ | -------- | ----------------------------------------------------- |
| `text`        | string | âœ…       | Text to convert to speech (English must be lowercase) |
| `lang`        | string | âœ…       | Language code (see table above)                       |
| `speaker_wav` | file   | âœ…       | Reference WAV file for speaker voice cloning          |

**Response**: `audio/wav` file (200 OK)

**Example**:

```python
import requests

response = requests.get(
    'https://harshil748-voiceapi.hf.space/Get_Inference',
    params={'text': 'à²¨à²®à²¸à³à²•à²¾à²°', 'lang': 'kannada'},
    files={'speaker_wav': open('reference.wav', 'rb')}
)

with open('output.wav', 'wb') as f:
    f.write(response.content)
```

---

## ğŸ“Š Technical Specifications

| Metric             | Value                                        |
| ------------------ | -------------------------------------------- |
| **Languages**      | 11 Indian languages                          |
| **Voice Variants** | 21 (male/female per language)                |
| **Training Data**  | 150+ hours (OpenSLR, Common Voice, IndicTTS) |
| **Model Size**     | 318MB (VITS), 998MB (Coqui)                  |
| **Inference Time** | 0.3-0.9 seconds per utterance                |
| **Sample Rate**    | 22.05kHz (VITS), 16kHz (MMS)                 |
| **Architecture**   | VITS + Meta MMS + Coqui TTS                  |
| **Deployment**     | HuggingFace Spaces (Docker)                  |
| **API Framework**  | FastAPI with Uvicorn                         |

---

## ğŸ—ï¸ Architecture

Built with a unified inference engine supporting heterogeneous model formats:

- **JIT Models (.pt)**: VITS models trained on 150+ hours for 19 voices
- **Coqui Checkpoints (.pth)**: Full checkpoints with config.json for Bhojpuri
- **HuggingFace MMS**: Meta's multilingual model for Gujarati

<details>
<summary><b>View Architecture Diagrams</b></summary>

#### System Architecture

![System Architecture](diagrams/system_architecture.png)

#### Data Flow

![Data Flow](diagrams/data_flow.png)

#### VITS Model Architecture

![Model Architecture](diagrams/model_architecture.png)

#### Training Pipeline

![Training Pipeline](diagrams/training_pipeline.png)

#### Voice Map (21 Voices Ã— 11 Languages)

![Voice Map](diagrams/voice_map.png)

</details>

---

## ğŸ› ï¸ Local Development

### Installation

```bash
git clone https://github.com/harshil748/VoiceAPI
cd VoiceAPI

python3 -m venv tts
source tts/bin/activate  # On Windows: tts\Scripts\activate

pip install -r requirements.txt
```

### Start Local Server

```bash
python -m src.cli serve --port 8000
```

Visit `http://localhost:8000/docs` for interactive API documentation.

### Generate Speech Locally

```bash
python -m src.cli synthesize \
  --text "à¤¨à¤®à¤¸à¥à¤¤à¥‡ à¤¦à¥‹à¤¸à¥à¤¤à¥‹à¤‚" \
  --voice hi_male \
  --output hello.wav

afplay hello.wav  # macOS
```

---

## ğŸ“ Repository Structure

```
VoiceAPI/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api.py           # FastAPI REST server
â”‚   â”œâ”€â”€ engine.py        # Unified TTS inference engine
â”‚   â”œâ”€â”€ tokenizer.py     # Indic script tokenization
â”‚   â”œâ”€â”€ config.py        # Language/voice configurations
â”‚   â””â”€â”€ cli.py           # Command-line interface
â”œâ”€â”€ models/              # Model storage (8GB, hosted on HF)
â”œâ”€â”€ training/            # Training scripts and configs
â”‚   â”œâ”€â”€ train_vits.py    # VITS training pipeline
â”‚   â”œâ”€â”€ prepare_dataset.py
â”‚   â””â”€â”€ export_model.py
â”œâ”€â”€ tests/               # API integration tests
â”œâ”€â”€ diagrams/            # Architecture diagrams (PNG)
â””â”€â”€ technical_report.tex # IEEE paper
```

---

## ğŸ“ Technical Report

Read the full technical writeup: [VoiceAPI.pdf](VoiceAPI.pdf)

**Key Contributions:**

- Trained 21 VITS models on 150+ hours of Indian language data
- Solved tokenizer alignment issues for Indic scripts
- Implemented lazy loading reducing memory by 60%
- Signal-based prosody control without retraining

---

## ğŸ™ Acknowledgments

- **OpenSLR**: Public speech datasets for 6 Indian languages
- **Common Voice**: Mozilla's crowdsourced speech corpus
- **IndicTTS**: IIT Madras speech synthesis resources
- **Meta MMS**: Massively multilingual speech models
- **HuggingFace**: Model hosting and deployment infrastructure

---

## ğŸ“œ License

- **Code**: MIT License
- **Models**: CC BY 4.0 (OpenSLR, IndicTTS), CC BY-NC 4.0 (MMS)

---

## ğŸ¤ Contributors

Built by Team VoiceAPI for **Voice Tech for All Hackathon 2024**:

- **Harshil Patel** - CHARUSAT University
- **Aashvi Maurya** - University of Allahabad
- **Pratyush Kumar Das** - FM University
- **Jaideep Amrabad** - NNRGI Hyderabad

---

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/harshil748/VoiceAPI/issues)
- **API Status**: Check [HuggingFace Space](https://huggingface.co/spaces/Harshil748/VoiceAPI)
- **Documentation**: [Live API Docs](https://harshil748-voiceapi.hf.space/docs)

---

<div align="center">

**â­ Star this repo if you find it useful!**

Built with â¤ï¸ for accessible healthcare in India

[Live API](https://harshil748-voiceapi.hf.space) â€¢ [Documentation](https://harshil748-voiceapi.hf.space/docs) â€¢ [GitHub](https://github.com/harshil748/VoiceAPI)

</div>
